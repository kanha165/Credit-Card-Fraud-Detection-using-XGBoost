# ğŸ’³ Credit Card Fraud Detection using XGBoost

## ğŸ“Œ Project Overview
Credit card fraud detection is a critical machine learning problem due to the highly imbalanced nature of real-world transaction data. Fraudulent transactions are extremely rare compared to normal transactions, which makes accuracy an unreliable metric.

This project implements an **end-to-end machine learning pipeline** using **XGBoost** to detect fraudulent credit card transactions. The focus is on improving **fraud recall** while maintaining strong overall performance. The project also includes **professional visualizations using Matplotlib**.

---

## ğŸ¯ Problem Statement
- Fraud cases account for less than **0.2%** of all transactions
- Traditional models fail on imbalanced datasets
- The key goal is to **minimize missed fraud cases (False Negatives)**

---

## ğŸ’¡ Solution Approach
- Used **XGBoost Classifier** for robust boosting-based learning
- Handled class imbalance using **scale_pos_weight**
- Evaluated the model using **ROC-AUC, Confusion Matrix, and Recall**
- Visualized results using **Matplotlib**
- Saved the trained model for reuse and testing

---

## ğŸ“Š Dataset Information

The dataset used in this project is the **Credit Card Fraud Detection Dataset**.

âš ï¸ **Note:**  
The dataset file is **very large in size**, which exceeds GitHubâ€™s file size limit.  
Therefore, the dataset is **not uploaded to this repository**.

You can download the dataset directly from Kaggle using the link below:

ğŸ”— **Kaggle Dataset Link:**  
https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

### Dataset Details
- Total transactions: 284,807  
- Fraud transactions: 492  
- Normal transactions: 284,315  
- Highly imbalanced dataset  
- Features `V1` to `V28` are PCA-transformed for privacy protection  

After downloading, place the `creditcard.csv` file in the project root directory before running the notebook.

---


### ğŸ”‘ Features
- `Time` â€“ Time elapsed since the first transaction  
- `V1` to `V28` â€“ PCA-transformed numerical features (privacy-protected)  
- `Amount` â€“ Transaction amount  
- `Class` â€“ Target variable  
  - `0` â†’ Normal  
  - `1` â†’ Fraud  

> PCA was applied to anonymize sensitive information while preserving important patterns.

---

## âš™ï¸ Tech Stack
- Python  
- NumPy  
- Pandas  
- Matplotlib  
- Scikit-learn  
- XGBoost  

---

## ğŸ¤– Machine Learning Model
- **Algorithm:** XGBoost Classifier  
- **Task:** Binary Classification  

### ğŸ”§ Hyperparameters
```python
n_estimators = 200
learning_rate = 0.05
max_depth = 5
subsample = 0.8
colsample_bytree = 0.8
scale_pos_weight = 100
eval_metric = "logloss"
random_state = 42


###ğŸ“ˆ Model Evaluation
To properly evaluate performance on imbalanced data, the following metrics were used:

ROC-AUC Score

Confusion Matrix

Recall (Fraud Class)



###ğŸ”¢ Results
ROC-AUC: ~0.97

Fraud Recall: ~87%

Missed Fraud Cases (FN): 13



## ğŸ“Š Visualizations
All graphs were created using Matplotlib:

ROC Curve (Dark Theme)

Confusion Matrix Heatmap

Train vs Test ROC Curve

Feature Importance Bar Chart

Images were saved using:


plt.savefig("image.png", dpi=300, bbox_inches="tight")
###ğŸ—‚ï¸ Project Structure

XGboost/
â”‚
â”‚
â”œâ”€â”€ _confusion_matrix.png        # Confusion Matrix graph (Matplotlib)
â”‚
â”œâ”€â”€ _roc.png                     # ROC Curve graph (Matplotlib)
â”‚
â”œâ”€â”€ creditcard.csv               # Original dataset (CSV)
â”‚
â”œâ”€â”€ creditcard.csv.zip           # Dataset zip file (backup / download)
â”‚
â”œâ”€â”€ train_Model.ipynb            # Main Jupyter Notebook (model training)
â”‚
â”œâ”€â”€ xgboost_fraud_model.pkl      # Saved trained XGBoost model
â”‚
â””â”€â”€ README.md                    # Project documentation (GitHub)

###â–¶ï¸ How to Run the Project
1ï¸âƒ£ Clone the Repository

git clone https://github.com/your-username/credit-card-fraud-detection-xgboost.git
cd credit-card-fraud-detection-xgboost
2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt
3ï¸âƒ£ Run the Notebook
Open fraud_detection.ipynb and run the cells step by step.

ğŸ§ª Testing the Model
The trained model can be tested using:

Test dataset

Manual transaction input

Custom fraud probability threshold

Example:


prob = model.predict_proba(sample)[0][1]
if prob >= 0.3:
    print("Fraud Transaction")
else:
    print("Normal Transaction")
ğŸš€ Future Improvements
Deploy the model using Streamlit

Add real-time transaction testing

Compare with AdaBoost and Random Forest

Apply SMOTE and analyze results

###ğŸ‘¤ Author
Kanha Patidar
B.Tech (CSIT)
Machine Learning & Data Science Enthusiast

ğŸ”— GitHub: https://github.com/kanha165
ğŸ”— LinkedIn: https://www.linkedin.com/in/kanha-patidar-837421290/

â­ Acknowledgment
Dataset provided by Kaggle.
This project is intended for learning, academic, and portfolio purposes.

â­ Support
If you like this project, please consider giving it a â­ on GitHub.

